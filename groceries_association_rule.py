# -*- coding: utf-8 -*-
"""Groceries-Association-Rule.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R_S7BtgJQYrerZ2lgsvzgsgYBz519ZbO

#Introduction

###The Groceries dataset is a popular dataset used for market basket analysis, association rule learning, and frequent itemset mining. It consists of transactions from a grocery store, where each transaction is a list of items purchased together by a customer.

###Key Characteristics:

##Transactional Data: The dataset is a collection of transactions, where each transaction is a list of items.
##Sparse Data: Typically, the dataset is sparse, meaning that most items do not appear in most transactions.
##Categorical Data: Items are represented by categorical names or IDs.

#Details of the dataset

###The dataset has 38765 rows of the purchase orders of people from the grocery stores. These orders can be analysed and association rules can be generated using Market Basket Analysis by algorithms like Apriori Algorithm.

#Association Rule Mining

###Market Basket Analysis is one of the key techniques used by large retailers to uncover associations between items. It works by looking for combinations of items that occur together frequently in transactions. To put it another way, it allows retailers to identify relationships between the items that people buy.

#Apriori Algorithm

###Apriori is an algorithm for frequent itemset mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent itemsets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.

#Source:

 https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset?

#Importing Necessary Libraries
"""

!pip install apyori #Installing apriori library

import numpy as np #NumPy is a powerful tool for numerical computations in Python.
import pandas as pd  #Pandas is a powerful library for data manipulation and analysis.
import seaborn as sns #Seaborn is a statistical data visualization library based on Matplotlib.
import matplotlib.pyplot as plt #Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.

"""#Loading the Dataset."""

df = pd.read_csv('Groceries_dataset.csv')

"""###We will now read the data from a CSV file into a Pandas DataFrame Let us have a look at how our dataset looks like using df.head()"""

df.head() #Displays the first 5 rows of the dataset.

df.columns #Displays columns names of the dataset.

df.shape #Displays the total count of the Rows and Columns respectively.

df.isnull().sum() # Displays the total count of the null values in the particular columns.

"""There is no null or missing value in the dataset."""

df.info() # Displays the total count of values present in the particular column along with the null count and data type.

"""#Checking for the Duplicate values"""

# Check for duplicate rows
duplicate_rows = df[df.duplicated()]

if duplicate_rows.empty:
    print("No duplicate values found.")
else:
    print("Duplicate values found:")
    print(duplicate_rows)

df.describe(include='all')

df['Date'] = pd.to_datetime(df['Date']) #Type-Conversion from Object to Dateime

"""###This code converts the data in the 'Date' column of the DataFrame df to datetime objects. This conversion is crucial for performing any time-series analysis or date-related operations such as filtering, extracting specific parts of the date (like year, month, day), and calculating date differences."""

df.info() #checking if the date columns are in proper format so we can use the data for further analysis.

df.head()

df.Member_number.nunique() #The df.Member_number.nunique() function is a Pandas method used to find the number of unique values in the Member_number column of a DataFrame df.

df.itemDescription.nunique() #The df.itemDescription.nunique() function is a Pandas method used to find the number of unique values in the itemDescription column of a DataFrame df.

df.Date.nunique() #The df.Date.nunique() function is a Pandas method used to find the number of unique values in the Date column of a DataFrame df.

"""## Creating Distribution of Item Sold"""

Item_distr = df.groupby(by = "itemDescription").size().reset_index(name='Frequency').sort_values(by = 'Frequency',ascending=False).head(10) #code performs a series of operations to find and display the top 10 most frequently occurring items in the itemDescription column of a DataFrame df.

Item_distr #Displays the result.

## Declaring variables
bars = Item_distr["itemDescription"]
height = Item_distr["Frequency"]
x_pos = np.arange(len(bars))

## Defining Figure Size
plt.figure(figsize=(16,9))

# Create bars
plt.bar(x_pos, height, color=(0.3, 0.4, 0.6, 0.6))

# Add title and axis names
plt.title("Top 10 Sold Items")
plt.xlabel("Item Name")
plt.ylabel("Number of Quantity Sold")

# Create names on the x-axis
plt.xticks(x_pos, bars)

# Shows graph
plt.show()

df_date=df.set_index(['Date']) ## Setting date as index for plotting purpose
df_date

df_date.resample("M")['itemDescription'].count().plot(figsize = (20,8), grid = True, title = "Number by Items Sold by Month").set(xlabel = "Date", ylabel = "Number of Items Sold")

"""Apriori is an algorithm for frequent itemset mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent itemsets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.

#Data Preparation
"""

cust_level = df[["Member_number", "itemDescription"]].sort_values(by = "Member_number", ascending = False) #This is often done to focus on the variables that are relevant for the analysis or modeling, reducing the complexity and memory usage of the DataFrame.
cust_level['itemDescription'] = cust_level['itemDescription'].str.strip() #To remove any leading or trailing white spaces from the itemDescription column.
cust_level

"""#Creating Transaction list"""

transactions = [a[1]['itemDescription'].tolist() for a in list(cust_level.groupby(['Member_number']))] #Combining all the items in list format for each customer.

"""#Train Model"""

from apyori import apriori #Importing apriori package

rules = apriori(transactions = transactions, min_support = 0.002, min_confidence = 0.05, min_lift = 3, min_length = 2, max_length = 2) #Model Creation

results = list(rules) #Storing results in list format for better visualisation.

results

"""The inspect(results) function processes the association rule mining results to extract and organize key metrics (LHS, RHS, support, confidence, lift) into a list of tuples. This list is then used to create a DataFrame, making it easier to analyze and visualize the association rules."""

#Creating user-defined function for arranging the results obtained from model into readable format

def inspect(results): #This defines a function named inspect that takes one parameter, results. The results parameter is expected to be a list of tuples or lists, each containing information about an association rule.
    lhs         = [tuple(result[2][0][0])[0] for result in results] #This line creates a list comprehension to extract the left-hand side (LHS) of each rule.
    rhs         = [tuple(result[2][0][1])[0] for result in results] #This line is similar to the previous one but extracts the right-hand side (RHS) of each rule
    supports    = [result[1] for result in results] #This line creates a list of support values for each rule. The support is usually found at the second index (result[1]) in each result tuple.
    confidences = [result[2][0][2] for result in results] #This line extracts the confidence values for each rule. The confidence is typically stored at result[2][0][2].
    lifts       = [result[2][0][3] for result in results] #This line extracts the lift values for each rule. The lift is typically found at result[2][0][3]
    return list(zip(lhs, rhs, supports, confidences, lifts)) #This line combines all the extracted values (lhs, rhs, supports, confidences, and lifts) into a list of tuples using the zip function. Each tuple contains the LHS, RHS, support, confidence, and lift of a rule.
resultsinDataFrame = pd.DataFrame(inspect(results), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift']) #This line calls the inspect function with the results and creates a DataFrame using the resulting list of tuples.

resultsinDataFrame.nlargest(n=10, columns="Lift") #Showing best possible scenarios

"""###The inspect(results) function processes the association rule mining results to extract and organize key metrics (LHS, RHS, support, confidence, lift) into a list of tuples. This list is then used to create a DataFrame, making it easier to analyze and visualize the association rules."""

